{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Fr2zyRoom/ISLES2017_LesionSegmentation_Tutorial/blob/main/ISLES2017_2dslice_lesion_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ISLES2017 Lesion Segmentation : 2D slice models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ADC dataset(2d slices version) ~ .npz\n",
    "!gdown \"https://drive.google.com/uc?id=1rk8_WePcRn8sGxOwyJjwJKoBossyxl1A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download packages\n",
    "!gdown \"https://drive.google.com/uc?id=1q8JDkCKe5Iv-Zzd_Rv17I1-alz1lM5qF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown \"https://drive.google.com/uc?id=1TO6t8lS1Ie4rMoZuW12XQk1Tw7S_eEm6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ISLES2017.zip -d ./ISLES2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip util.zip -d ./util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip data.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall albumentations==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall matplotlib\n",
    "!pip install matplotlib==3.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import PIL.Image as Image\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from util.util import *\n",
    "from util.visualize import *\n",
    "from data.dataset_2d import *\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test(file_id, val_case):\n",
    "    if file_id in val_case:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "FOLD = 5\n",
    "random_seed = 50\n",
    "\n",
    "train_df = pd.read_csv(\"./ISLES2017/ISLES2017_Training_clr.csv\")\n",
    "case_name = train_df[\"Case SMIR ID 1\"].values\n",
    "mrss = train_df[\"MRSScore\"].values\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLD, random_state=random_seed, shuffle=True)\n",
    "\n",
    "skf.get_n_splits(case_name, mrss)\n",
    "\n",
    "train_df_split = copy.deepcopy(train_df)\n",
    "\n",
    "num=1\n",
    "for train_index, test_index in skf.split(case_name, mrss):\n",
    "    fold_num = 'fold'+str(num)\n",
    "    X_train, X_val = case_name[train_index], case_name[test_index]\n",
    "    #y_train, y_test = mrss[train_index], mrss[test_index]\n",
    "    #X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=random_seed, shuffle=True, stratify=y_train)\n",
    "    train_df_split[fold_num] = train_df_split[\"Case SMIR ID 1\"].map(lambda x: split_train_val_test(x, val_case=X_val))\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_df_path = \"./ISLES2017/ISLES2017_Training_clr_\" + str(FOLD) + \"fold.csv\"\n",
    "train_df_split.to_csv(kfold_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ISLES_ADCLesionSegDataset(\n",
    "    dataset_dir=\"./ISLES2017/ISLES2017_Training_2d_ADC\", \n",
    "    df_path=\"./ISLES2017/ISLES2017_Training_clr_5fold.csv\",\n",
    "    img_loader=img_loader, \n",
    "    mask_loader=mask_loader,\n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    kfold=1,\n",
    "    mode='train'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ISLES_ADCLesionSegDataset(\n",
    "    dataset_dir=\"./ISLES2017/ISLES2017_Training_2d_ADC\", \n",
    "    df_path=\"./ISLES2017/ISLES2017_Training_clr_5fold.csv\",\n",
    "    img_loader=img_loader, \n",
    "    mask_loader=mask_loader,\n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    kfold=1,\n",
    "    mode='val'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataset = ISLES_ADCLesionSegDataset(\n",
    "    dataset_dir=\"./ISLES2017/ISLES2017_Training_2d_ADC\", \n",
    "    df_path=\"./ISLES2017/ISLES2017_Training_clr_5fold.csv\",\n",
    "    img_loader=img_loader, \n",
    "    mask_loader=mask_loader,\n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(resize=(256,256),convert=False),\n",
    "    kfold=1,\n",
    "    mode='train'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# check augmentation \n",
    "for i in range(10,40):\n",
    "    image, mask = aug_dataset[i] \n",
    "    visualize(image=visualize_grayscale(np.squeeze(image)), mask=visualize_grayscale(np.squeeze(mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            #self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            #self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./ADC_ckpt/2d_ckpt/UNet_resnet152\"\n",
    "gen_new_dir(save_path)\n",
    "###############################\n",
    "trial = 1\n",
    "n_epoches = 10000\n",
    "LR = 0.0001\n",
    "LR_DECREASE = 1e-5\n",
    "lr_decrease_epoch = 70\n",
    "BATCH_SIZE = 16\n",
    "patience= 15\n",
    "###############################\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True, drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, \n",
    "                                         shuffle=False)\n",
    "\n",
    "ENCODER = 'resnet152'\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=None, \n",
    "    in_channels=1,\n",
    "    classes=1, \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=LR),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners \n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model for 40 epochs\n",
    "\n",
    "max_score = 0\n",
    "with open(os.path.join(save_path, f'results{str(trial).zfill(2)}.csv'), 'w') as f:\n",
    "    f.write('epoch,train_loss,train_score,valid_loss,valid_score\\n')\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "for epoch in range(0, n_epoches):\n",
    "    \n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(val_loader)\n",
    "    \n",
    "    with open(os.path.join(save_path, f'results{str(trial).zfill(2)}.csv'), 'a') as f:\n",
    "            f.write('%03d,%0.6f,%0.6f,%0.6f,%0.6f\\n' % (\n",
    "                (epoch + 1),\n",
    "                train_logs['dice_loss'],\n",
    "                train_logs['iou_score'],\n",
    "                valid_logs['dice_loss'],\n",
    "                valid_logs['iou_score'],\n",
    "            ))\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, os.path.join(save_path, f'best_model{str(trial).zfill(2)}.pth'))\n",
    "        print('New Record!')\n",
    "        \n",
    "    torch.save(model, os.path.join(save_path, f'final_model{str(trial).zfill(2)}.pth'))\n",
    "    \n",
    "    early_stopping(valid_logs['dice_loss'], model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    \n",
    "    if epoch == lr_decrease_epoch:\n",
    "        optimizer.param_groups[0]['lr'] = LR_DECREASE\n",
    "        print(f'Decrease decoder learning rate to {LR_DECREASE}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ISLES_ADCLesionSegDataset(\n",
    "    dataset_dir=\"./ISLES2017/ISLES2017_Training_2d_ADC\", \n",
    "    df_path=\"./ISLES2017/ISLES2017_Training_clr_5fold.csv\",\n",
    "    img_loader=img_loader, \n",
    "    mask_loader=mask_loader,\n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    kfold=1,\n",
    "    mode='val'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_val_dataset = ISLES_ADCLesionSegDataset(\n",
    "    dataset_dir=\"./ISLES2017/ISLES2017_Training_2d_ADC\", \n",
    "    df_path=\"./ISLES2017/ISLES2017_Training_clr_5fold.csv\",\n",
    "    img_loader=img_loader, \n",
    "    mask_loader=mask_loader,\n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(resize=(256,256), convert=False),\n",
    "    kfold=1,\n",
    "    mode='val'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "save_path = \"./ADC_ckpt/2d_ckpt/UNet_resnet152\"\n",
    "best_model = torch.load(os.path.join(save_path, 'best_model01.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model=best_model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "logs = test_epoch.run(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.read_csv(os.path.join(save_path,'results01.csv'))\n",
    "fig,ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(np.array(train_history['train_loss']), 'b')\n",
    "ax[0].plot(np.array(train_history['valid_loss']), 'r')\n",
    "\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(np.array(train_history['train_score']), 'b')\n",
    "ax[1].plot(np.array(train_history['valid_score']), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = []\n",
    "\n",
    "for data in val_loader:\n",
    "    images, labels = data\n",
    "    images = images.to(DEVICE)\n",
    "    masks = labels.to(DEVICE)\n",
    "    pr_mask = best_model.predict(images)\n",
    "    predict_masks.append(pr_mask.cpu().numpy().round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = np.squeeze(np.vstack(predict_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,63):\n",
    "    image, mask = vis_val_dataset[i] \n",
    "    predict= predict_masks[i]\n",
    "    image_rgb = visualize_grayscale(np.squeeze(image))\n",
    "    predict= predict.astype(np.uint8)\n",
    "    predict= predict[:,:,np.newaxis]\n",
    "    intersect_mask = mask*predict\n",
    "    only_mask = np.where((mask-intersect_mask)==1, 1, 0)\n",
    "    only_pred = np.where((predict-intersect_mask)==1, 1, 0)\n",
    "    tp_np_mask = np.concatenate([only_pred,intersect_mask,only_mask], axis=-1)*255\n",
    "    vis = image_rgb/2 + tp_np_mask/2\n",
    "    vis = vis.astype(np.uint8)\n",
    "    visualize(image=image_rgb, result=tp_np_mask, visualize= vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code reference: https://gist.github.com/gergf/acd8e3fd23347cb9e6dc572f00c63d79\n",
    "def dice(true_mask, pred_mask, non_seg_score=0.0):\n",
    "    \"\"\"\n",
    "        Computes the Dice coefficient.\n",
    "        Args:\n",
    "            true_mask : Array of arbitrary shape.\n",
    "            pred_mask : Array with the same shape than true_mask.  \n",
    "        \n",
    "        Returns:\n",
    "            A scalar representing the Dice coefficient between the two segmentations. \n",
    "        \n",
    "    \"\"\"\n",
    "    assert true_mask.shape == pred_mask.shape\n",
    "\n",
    "    true_mask = np.asarray(true_mask).astype(np.bool_)\n",
    "    pred_mask = np.asarray(pred_mask).astype(np.bool_)\n",
    "\n",
    "    # If both segmentations are all zero, the dice will be 1. (Developer decision)\n",
    "    im_sum = true_mask.sum() + pred_mask.sum()\n",
    "    if im_sum == 0:\n",
    "        return non_seg_score\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(true_mask, pred_mask)\n",
    "    return 2. * intersection.sum() / im_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_avg = 0\n",
    "cnt = 0\n",
    "for i in range(len(vis_val_dataset)):\n",
    "    image, mask = vis_val_dataset[i] \n",
    "    if (predict_masks[i].max() != 0.) & (mask.max() != 0.):\n",
    "        dice_avg += dice(np.squeeze(mask.astype(np.uint8)), predict_masks[i].astype(np.uint8))\n",
    "        cnt += 1\n",
    "    else:\n",
    "        pass\n",
    "dice_avg /= cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
